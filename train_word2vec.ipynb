{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T10:34:18.133800Z",
     "start_time": "2017-06-16T10:34:18.127931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from glob import glob\n",
    "import ujson as json\n",
    "\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T10:34:55.740099Z",
     "start_time": "2017-06-16T10:34:55.730399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대선: 총 0개의 기사 (전체의 0.0000%)\n",
      "문재인: 총 0개의 기사 (전체의 0.0000%)\n",
      "안철수: 총 0개의 기사 (전체의 0.0000%)\n",
      "홍준표: 총 0개의 기사 (전체의 0.0000%)\n",
      "유승민: 총 0개의 기사 (전체의 0.0000%)\n",
      "심상정: 총 0개의 기사 (전체의 0.0000%)\n"
     ]
    }
   ],
   "source": [
    "keywords = [\"대선\", \"문재인\", \"안철수\", \"홍준표\", \"유승민\", \"심상정\"]\n",
    "a = 154092\n",
    "for keyword in keywords:\n",
    "    files = glob(\"crawlwed_articles/{}/*.json\".format(keyword))\n",
    "    totalNum = 0\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            totalNum += len(json.load(f))\n",
    "    print(\"{}: 총 {}개의 기사 (전체의 {:.4f}%)\".format(keyword, totalNum, totalNum/a*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T10:49:35.986688Z",
     "start_time": "2017-06-16T10:49:35.855053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "27"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 1000 exceeded with 3890 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T10:34:56.564410Z",
     "start_time": "2017-06-16T10:34:56.559676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(files[0]) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2017-05-06',\n",
       " 'text': \"앵커\\n바른정당 유승민 후보는 대통령이 되면, 한·일 정부 간 위안부 합의를 파기하고 재협상에 나서겠다고 밝혔습니다.정의당 심상정 후보는 자신이 홍준표 후보를 꺾는 게 촛불 민심에 부합하는 일이라며 날을 세웠습니다.안윤학 기자입니다.\\n기자\\n바른정당 유승민 후보는 집단 탈당 사태 이후 수도권에서부터 지지율이 오르고 있다고 보고 사흘째 수도권 민심 잡기에 집중했습니다.수원 월드컵경기장과 잠실야구장 등 인파가 몰리는 지역을 돌며 보수의 개혁에 힘을 실어달라고 호소했습니다.위안부 피해자 할머니들을 위한 어버이날 행사에도 참석해, 일본 정부와의 위안부 합의를 파기하고 재협상에 나서겠다고 약속했습니다. 정의당 심상정 후보도 수도권 유세에 총력을 기울였습니다.촛불 혁명의 완성은 누가 당선되느냐보다는 적폐 세력으로 지목한 홍준표 후보를 자신이 꺾느냐 못 꺾느냐에 달려 있다며 집중 공세를 퍼부었습니다. 심 후보는 또 민주당이 홍준표 후보를 염두에 두고 정권교체가 위태롭다며 '공포 마케팅'을 하는 것은 촛불 민심을 모욕하는 것이라며 즉각 중단을 촉구했습니다.YTN 안윤학 입니다.\",\n",
       " 'title': '유승민 \"위안부 합의 재협상\"...심상정 \"적폐 홍준표 청산해야\"'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n"
     ]
    }
   ],
   "source": [
    "articleList = []\n",
    "titles = set()\n",
    "articleNum = 0\n",
    "\n",
    "for keyword in keywords:\n",
    "    files = glob(\"cralwed_articles/{}/*.json\".format(keyword))\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            articles = json.load(f)\n",
    "        for article in articles:\n",
    "            if article['title'] not in titles:\n",
    "                # 기사 중복되지 않는 것들만 처리\n",
    "                titles.add(article['title'])\n",
    "                articleList.append(article)\n",
    "                articleNum += 1\n",
    "                \n",
    "                if articleNum % 10000 == 0:\n",
    "                    print(articleNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "related_articles = defaultdict(list)\n",
    "\n",
    "for article in articleList:\n",
    "    for keyword in keywords[1:]:\n",
    "        if keyword in article['title']:\n",
    "            related_articles[keyword].append(article['title'])\n",
    "\n",
    "with open(\"related_articles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(related_articles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"articles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(articleList, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"articles.pkl\", \"rb\") as f:\n",
    "    articleList = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n"
     ]
    }
   ],
   "source": [
    "spamTag = set(['URL', 'Email', 'KoreanParticle', 'Foreign', 'Number', 'Punctuation'])\n",
    "wordsList = []\n",
    "for i, article in enumerate(articleList):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "\n",
    "    words = []\n",
    "    p = twitter.pos(article['text'], stem=True, norm=True)\n",
    "    for pos in p:\n",
    "        if pos[1] not in spamTag:\n",
    "            words.append(pos[0])\n",
    "    wordsList.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(wordsList, size=200, min_count=5, workers=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('word2vec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = model['문재인']\n",
    "b = model['대통령']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 문재인 and 진보: 0.34033064805568114\n",
      "Similarity between 홍준표 and 진보: 0.24932029585687634\n",
      "Similarity between 안철수 and 진보: 0.2935491661969409\n",
      "Similarity between 유승민 and 진보: 0.3013114592999173\n",
      "Similarity between 심상정 and 진보: 0.36947003451293675\n",
      "\n",
      "Similarity between 문재인 and 보수: 0.33152449313652027\n",
      "Similarity between 홍준표 and 보수: 0.4095070890920629\n",
      "Similarity between 안철수 and 보수: 0.32456712444940394\n",
      "Similarity between 유승민 and 보수: 0.3791166938994421\n",
      "Similarity between 심상정 and 보수: 0.25648218122290956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "candidates = ['문재인', '홍준표', '안철수', '유승민', '심상정']\n",
    "tendencies = ['진보', '보수']\n",
    "for tendency in tendencies:\n",
    "    for candidate in candidates:\n",
    "        print(\"Similarity between {} and {}: {}\".format(candidate, tendency, model.wv.similarity(candidate, tendency)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/376736b75ea18ab8cffe51c465b60cd0"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "github/Korean-presidential-election-visualization/train_word2vec.ipynb",
    "public": true
   },
   "id": "376736b75ea18ab8cffe51c465b60cd0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "number",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "491px",
    "left": "910px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
